{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 8509505,
     "sourceType": "datasetVersion",
     "datasetId": 5079570
    },
    {
     "sourceId": 8468372,
     "sourceType": "datasetVersion",
     "datasetId": 5049147
    },
    {
     "sourceId": 8509381,
     "sourceType": "datasetVersion",
     "datasetId": 5079499
    }
   ],
   "dockerImageVersionId": 30699,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:38.454574Z",
     "iopub.execute_input": "2024-05-30T13:55:38.455176Z",
     "iopub.status.idle": "2024-05-30T13:55:38.483668Z",
     "shell.execute_reply.started": "2024-05-30T13:55:38.455147Z",
     "shell.execute_reply": "2024-05-30T13:55:38.482952Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:38.485069Z",
     "iopub.execute_input": "2024-05-30T13:55:38.485331Z",
     "iopub.status.idle": "2024-05-30T13:55:38.517305Z",
     "shell.execute_reply.started": "2024-05-30T13:55:38.485308Z",
     "shell.execute_reply": "2024-05-30T13:55:38.516446Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone \"https://github.com/RuslanZaripov/rhtr.git\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:38.518456Z",
     "iopub.execute_input": "2024-05-30T13:55:38.518806Z",
     "iopub.status.idle": "2024-05-30T13:55:42.766142Z",
     "shell.execute_reply.started": "2024-05-30T13:55:38.518773Z",
     "shell.execute_reply": "2024-05-30T13:55:42.764593Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Cloning into 'rhtr'...\nremote: Enumerating objects: 808, done.\u001B[K\nremote: Counting objects: 100% (295/295), done.\u001B[K\nremote: Compressing objects: 100% (203/203), done.\u001B[K\nremote: Total 808 (delta 164), reused 206 (delta 86), pack-reused 513\u001B[K\nReceiving objects: 100% (808/808), 53.92 MiB | 34.21 MiB/s, done.\nResolving deltas: 100% (507/507), done.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /kaggle/working/rhtr"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:42.768576Z",
     "iopub.execute_input": "2024-05-30T13:55:42.768916Z",
     "iopub.status.idle": "2024-05-30T13:55:42.792814Z",
     "shell.execute_reply.started": "2024-05-30T13:55:42.768887Z",
     "shell.execute_reply": "2024-05-30T13:55:42.791775Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/working/rhtr\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "workdir = os.getcwd()\n",
    "workdir "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:42.794525Z",
     "iopub.execute_input": "2024-05-30T13:55:42.795110Z",
     "iopub.status.idle": "2024-05-30T13:55:42.818314Z",
     "shell.execute_reply.started": "2024-05-30T13:55:42.795079Z",
     "shell.execute_reply": "2024-05-30T13:55:42.817256Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/kaggle/working/rhtr'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_dir = f'{workdir}/data'\n",
    "data_dir"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:42.819822Z",
     "iopub.execute_input": "2024-05-30T13:55:42.820282Z",
     "iopub.status.idle": "2024-05-30T13:55:42.838870Z",
     "shell.execute_reply.started": "2024-05-30T13:55:42.820243Z",
     "shell.execute_reply": "2024-05-30T13:55:42.837722Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/kaggle/working/rhtr/data'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir {data_dir}"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:57.211922Z",
     "iopub.execute_input": "2024-05-30T13:55:57.212273Z",
     "iopub.status.idle": "2024-05-30T13:55:58.182374Z",
     "shell.execute_reply.started": "2024-05-30T13:55:57.212245Z",
     "shell.execute_reply": "2024-05-30T13:55:58.181430Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "mkdir: cannot create directory '/kaggle/working/rhtr/data': File exists\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir /kaggle/working/rhtr/models/\n",
    "!mkdir /kaggle/working/rhtr/models/segmentation"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:55:58.184177Z",
     "iopub.execute_input": "2024-05-30T13:55:58.184483Z",
     "iopub.status.idle": "2024-05-30T13:56:00.141457Z",
     "shell.execute_reply.started": "2024-05-30T13:55:58.184455Z",
     "shell.execute_reply": "2024-05-30T13:56:00.140225Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers onnxruntime onnx imutils jiwer > /dev/null"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:56:00.143191Z",
     "iopub.execute_input": "2024-05-30T13:56:00.144039Z",
     "iopub.status.idle": "2024-05-30T13:56:17.370745Z",
     "shell.execute_reply.started": "2024-05-30T13:56:00.144001Z",
     "shell.execute_reply": "2024-05-30T13:56:17.369574Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cp /kaggle/input/linknet-12-2/linknet_12_2.onnx /kaggle/working/rhtr/models/segmentation/linknet_12_2.onnx"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:56:17.373447Z",
     "iopub.execute_input": "2024-05-30T13:56:17.374471Z",
     "iopub.status.idle": "2024-05-30T13:56:19.436259Z",
     "shell.execute_reply.started": "2024-05-30T13:56:17.374420Z",
     "shell.execute_reply": "2024-05-30T13:56:19.434829Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import os\n",
    "\n",
    "def download_model(model_path, model_name):\n",
    "    \"\"\"Download a Hugging Face model and processor to the specified directory\"\"\"\n",
    "    # Check if the directory already exists\n",
    "    if not os.path.exists(model_path):\n",
    "        # Create the directory\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "    # Save the model and processor to the specified directory\n",
    "    model.save_pretrained(model_path)\n",
    "    processor.save_pretrained(model_path)\n",
    "\n",
    "\n",
    "download_model('/kaggle/working/rhtr/models/tr_ocr', 'zarus03/rhtr')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:56:19.437862Z",
     "iopub.execute_input": "2024-05-30T13:56:19.438254Z",
     "iopub.status.idle": "2024-05-30T13:57:08.056616Z",
     "shell.execute_reply.started": "2024-05-30T13:56:19.438215Z",
     "shell.execute_reply": "2024-05-30T13:57:08.055756Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024-05-30 13:56:28.366437: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-30 13:56:28.366543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-30 13:56:28.529855: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "preprocessor_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7cc1154c63d4ff284cc457be250f43d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41fcd99b6d3842e3bba437c47123cc52"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "498f5c5290a347598703b9c571fe2a62"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce2d833e6eb94e6bb8eecbdb126519b7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "352887db2e8e49cda0093e2abc399b61"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a69bb1e94977430695838bb66bef1153"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/4.67k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48d5c814449349f5a7a1615ad91de697"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2c2d2f332ea4072a5b5a9f993852d68"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/205 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1afddfd100d640e89b1c3086ba3dc080"
      }
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 64}\nRemoved shared tensor {'decoder.output_projection.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import src.pipeline.pipeline_predictor\n",
    "\n",
    "predictor = src.pipeline.pipeline_predictor.PipelinePredictor(\n",
    "    config_path='src/pipeline/scripts/pipeline_config.json'\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T13:57:08.058409Z",
     "iopub.execute_input": "2024-05-30T13:57:08.058975Z",
     "iopub.status.idle": "2024-05-30T13:57:18.081123Z",
     "shell.execute_reply.started": "2024-05-30T13:57:08.058947Z",
     "shell.execute_reply": "2024-05-30T13:57:18.080301Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "WordSegmentation input {'model_name': 'UNet', 'model_path': 'models/segmentation/linknet_12_2.onnx', 'config_path': 'src/segmentation/configs/train_config.json'}\ncwd='/kaggle/working/rhtr' config_path='src/segmentation/configs/train_config.json'\nOpticalCharacterRecognition input {'model_name': 'TrOCR', 'model_path': 'models/tr_ocr/', 'ocr_classes': ['handwritten_text_shrinked_mask1']}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "def process(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    try:\n",
    "        rotated_image, data = predictor.predict(image)\n",
    "    except Exception as e:\n",
    "        print(f\"Wasn't processed {file_path=}\")\n",
    "        \n",
    "    filtered_words = list(filter(\n",
    "        lambda prediction: prediction['class_name'] in predictor.get_prediction_classes(),\n",
    "        data['predictions']\n",
    "    ))\n",
    "    \n",
    "    word_count = len(filtered_words)\n",
    "    print(f\"{word_count=}\")\n",
    "\n",
    "    # # Sorting by word_idx\n",
    "    sorted_predictions = sorted(\n",
    "        filtered_words,\n",
    "        key=lambda prediction: prediction['word_idx'] if 'word_idx' in prediction.keys() else word_count)\n",
    "\n",
    "    words_string = ' '.join(prediction['text'] for prediction in sorted_predictions)\n",
    "    \n",
    "    return words_string"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T14:05:56.042391Z",
     "iopub.execute_input": "2024-05-30T14:05:56.043335Z",
     "iopub.status.idle": "2024-05-30T14:05:56.142390Z",
     "shell.execute_reply.started": "2024-05-30T14:05:56.043303Z",
     "shell.execute_reply": "2024-05-30T14:05:56.141502Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ocr_text = process('/kaggle/input/hwr200/HWR200/images/original0_LightPhoto_1.jpg')\n",
    "ocr_text"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T14:07:42.416674Z",
     "iopub.execute_input": "2024-05-30T14:07:42.417057Z",
     "iopub.status.idle": "2024-05-30T14:08:19.586692Z",
     "shell.execute_reply.started": "2024-05-30T14:07:42.417028Z",
     "shell.execute_reply": "2024-05-30T14:08:19.585831Z"
    },
    "trusted": true
   },
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": "image.shape=(3818, 3024, 3)\nFunction __call__ Took 13.2577 seconds\nFunction __call__ Took 22.0328 seconds\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "word_count=132\n",
     "output_type": "stream"
    },
    {
     "execution_count": 38,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Что главное 8 жизни. семья Что гла он а 8 тиз- имен работа ни . семья ими работа - бота проблем ма, над которой рассуждает Д. Ю. Бе- ли ченно, Писа тель для полного расиры тся поста бленного боироса выбирает форму письма другу, С роде котор ому герой откровенно ряет 8се обои разл об имения, Мужчина, серьезно за солнения, думы бается, что для него ба жнее работа или силья, В результат те - они выбирает се мью. Д. Ю. Бели гемно, сам от ещ шестер бы рад такому де- ре- тей, несомненно, автора шению героя. Позиция проявляется гетко б предложении 22: 1, Семья - она важнее. Я, раз- делею тому зрения автора. семья- это, пожалуй, то единств вечное место, где тебя боепринимают томим, какой та есть, р радуются тбоим успеха м. и неголятся вместе'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "gt_text = open('/kaggle/input/hwr200/HWR200/gts/original0_LightPhoto_1.txt').read()\n",
    "gt_text"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T14:08:28.914670Z",
     "iopub.execute_input": "2024-05-30T14:08:28.915064Z",
     "iopub.status.idle": "2024-05-30T14:08:29.020384Z",
     "shell.execute_reply.started": "2024-05-30T14:08:28.915036Z",
     "shell.execute_reply": "2024-05-30T14:08:29.019588Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": [
    {
     "execution_count": 39,
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Что главное в жизни: семья или работа? Что главное в жизни: семья или работа–вот проблема, над которой рассуждает Д.\\xa0Ю.\\xa0Беличенко. Писатель для полного раскрытия поставленного вопроса выбирает форму письма другу, которому герой откровенно доверяет все свои размышления, сомнения. Мужчина, серьезно задумывается, что для него важнее: работа или семья. В результате он выбирает последнее. Д. Ю. Беличенко, сам отец шестерых детей, несомненно, рад такому решению героя. Позиция автора проявляется четко в предложении 22: «Семья — она важнее». Я разделяю точку зрения автора: семья — это, пожалуй, то единственное место, где тебя воспринимают таким, какой ты есть, радуются твоим успехам и печалятся вместе'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def calculate_cosine_distance(text1, text2):\n",
    "    # Tokenize the texts\n",
    "    texts = [text1, text2]\n",
    "\n",
    "    # texts = list(map(preprocess_text, texts))\n",
    "\n",
    "    vectorizer = CountVectorizer(encoding='latin-1', binary=False).fit(texts)\n",
    "    vectors = vectorizer.transform(texts)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "\n",
    "    # The cosine similarity matrix will have cosine similarity values for all pairs of texts\n",
    "    # Since we only have two texts, we return the value at (0, 1) or (1, 0)\n",
    "    return cosine_sim[0][1]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T14:08:30.335109Z",
     "iopub.execute_input": "2024-05-30T14:08:30.335601Z",
     "iopub.status.idle": "2024-05-30T14:08:30.458930Z",
     "shell.execute_reply.started": "2024-05-30T14:08:30.335555Z",
     "shell.execute_reply": "2024-05-30T14:08:30.457867Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "distance = calculate_cosine_distance(\"This is the first text.\", \"text\")\n",
    "print(\"Cosine distance:\", distance)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T14:08:31.034807Z",
     "iopub.execute_input": "2024-05-30T14:08:31.035750Z",
     "iopub.status.idle": "2024-05-30T14:08:31.138524Z",
     "shell.execute_reply.started": "2024-05-30T14:08:31.035689Z",
     "shell.execute_reply": "2024-05-30T14:08:31.137411Z"
    },
    "trusted": true
   },
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "text": "Cosine distance: 0.4472135954999579\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T14:08:46.723770Z",
     "iopub.execute_input": "2024-05-30T14:08:46.724686Z",
     "iopub.status.idle": "2024-05-30T14:08:47.984497Z",
     "shell.execute_reply.started": "2024-05-30T14:08:46.724650Z",
     "shell.execute_reply": "2024-05-30T14:08:47.983440Z"
    },
    "trusted": true
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cousine_score = calculate_cosine_distance(ocr_text, gt_text)\n",
    "wer_score = wer.compute(predictions=[ocr_text], references=[gt_text])\n",
    "cer_score = cer.compute(predictions=[ocr_text], references=[gt_text])\n",
    "print(f\"{cousine_score=} {wer_score=} {cer_score=}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-30T14:08:47.986284Z",
     "iopub.execute_input": "2024-05-30T14:08:47.986608Z",
     "iopub.status.idle": "2024-05-30T14:08:48.107310Z",
     "shell.execute_reply.started": "2024-05-30T14:08:47.986580Z",
     "shell.execute_reply": "2024-05-30T14:08:48.106418Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": "cousine_score=0.6458489066525221 wer_score=0.89 cer_score=0.2621082621082621\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
